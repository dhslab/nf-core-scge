/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    nf-core/scge Nextflow config file
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    Default config options for all compute environments
----------------------------------------------------------------------------------------
*/

// Global default params, used in configs
params {
    input                      = null
    outdir                     = null
    data_path                  = null
    mgi                        = false
    id                         = null
    tumorid                    = null
    normalid                   = null
    
    // References
    fasta                      = "/storage1/fs1/dspencer/Active/clinseq/projects/scge/data/refdata/hg38_PLVM_CD19_CARv4_cd34/hg38_PLVM_CD19_CARv4_cd34.fa"
    fasta_index                = "${fasta}.fai"
    
    user_group                 = "compute-dspencer"
    queue                      = "dspencer"
    job_group_name             = "/dnidhi"

    run_dragen                 = true
    run_analysis               = false
 
    // VEP annotation cache
    assay_inputs {
        VEP_cache              = "/storage1/fs1/dspencer/Active/clinseq/projects/chromoseq/refdata/VEP_cache"
        cytobands              = null
        hotspot_vcf            = null
        hotspot_vcf_index      = null
    }

    aws_dragen_container        = 'ghcr.io/dhslab/docker-dragen:el7.4.2.4'
    dragen_container           = "etycksen/dragen4:4.2.4"

    // dragen options
    alignment_file_format       = 'CRAM'
    mark_duplicates             = true
    
    // Dragen inputs
    dragen_inputs {
        dragen_hash                 = "/storage1/fs1/dspencer/Active/clinseq/projects/scge/data/refdata/hg38_PLVM_CD19_CARv4_cd34"
        snv_noisefile               = "/storage1/fs1/dspencer/Active/clinseq/projects/chromoseq/refdata/dragen_align_inputs/hg38/dragen_v1.0_systematic_noise.nextera_wgs.120920.bed.gz"
        sv_noisefile                = "/storage1/fs1/dspencer/Active/clinseq/projects/chromoseq/refdata/dragen_align_inputs/hg38/WGS_v2.0.0_hg38_sv_systematic_noise.bedpe.gz"
        dbsnp                       = "/storage1/fs1/dspencer/Active/clinseq/projects/chromoseq/refdata/dragen_align_inputs/hg38/dbsnp.vcf.gz"
        dbsnp_index                 = "/storage1/fs1/dspencer/Active/clinseq/projects/chromoseq/refdata/dragen_align_inputs/hg38/dbsnp.vcf.gz.tbi"
        pop_af_vcf                  = "/storage1/fs1/dspencer/Active/clinseq/projects/chromoseq/refdata/dragen_align_inputs/hg38/1000G_phase1.snps.high_confidence.hg38.vcf.gz"
        pop_af_vcf_index            = "/storage1/fs1/dspencer/Active/clinseq/projects/chromoseq/refdata/dragen_align_inputs/hg38/1000G_phase1.snps.high_confidence.hg38.vcf.gz.tbi"
        dragen_adapter1             = "/storage1/fs1/dspencer/Active/clinseq/projects/chromoseq/refdata/dragen_align_inputs/hg38/dragen_adapter1.fa"
        dragen_adapter2             = "/storage1/fs1/dspencer/Active/clinseq/projects/chromoseq/refdata/dragen_align_inputs/hg38/dragen_adapter2.fa"
        input_cram_reference        = "${params.fasta}"
        input_cram_reference_index  = "${params.fasta_index}"        
    }

    // TODO nf-core: Specify your pipeline's command line flags
    // Input options
    // References
    genome                     = null
    igenomes_base              = 's3://ngi-igenomes/igenomes/'
    igenomes_ignore            = false
    

    // MultiQC options
    multiqc_config             = null
    multiqc_title              = null
    multiqc_logo               = null
    max_multiqc_email_size     = '25.MB'
    multiqc_methods_description = null

    // Boilerplate options
    outdir                     = null
    publish_dir_mode           = 'copy'
    email                      = null
    email_on_fail              = null
    plaintext_email            = false
    monochrome_logs            = false
    hook_url                   = null
    help                       = false
    version                    = false

    // Config options
    config_profile_name        = null
    config_profile_description = null
    custom_config_version      = 'master'
    custom_config_base         = "https://raw.githubusercontent.com/nf-core/configs/${params.custom_config_version}"
    config_profile_contact     = null
    config_profile_url         = null
    

    // Max resource options
    // Defaults only, expecting to be overwritten
    max_memory                 = '128.GB'
    max_cpus                   = 16
    max_time                   = '240.h'

    // Schema validation default options
    validationFailUnrecognisedParams = false
    validationLenientMode            = false
    validationSchemaIgnoreParams     = 'genomes,igenomes_base'
    validationShowHiddenParams       = false
    validate_params                  = true

}

// Load base.config by default for all pipelines
includeConfig 'conf/base.config'

// Load nf-core custom profiles from different Institutions
try {
    includeConfig "${params.custom_config_base}/nfcore_custom.config"
} catch (Exception e) {
    System.err.println("WARNING: Could not load nf-core/config profiles: ${params.custom_config_base}/nfcore_custom.config")
}

// Load nf-core/scge custom profiles from different institutions.
// Warning: Uncomment only if a pipeline-specific institutional config already exists on nf-core/configs!
// try {
//   includeConfig "${params.custom_config_base}/pipeline/scge.config"
// } catch (Exception e) {
//   System.err.println("WARNING: Could not load nf-core/config/scge profiles: ${params.custom_config_base}/pipeline/scge.config")
// }
profiles {

    stub { includeConfig 'conf/stub.config' } // local executor for testing

    ris {
        executor.queueSize        = 20
        executor.submitRateLimit  = '1/1sec'
        process {
            executor                  = "lsf"
            clusterOptions            =   { "-a 'docker(${task.container})' -q ${params.queue} -G ${params.user_group} -g ${params.job_group_name}" }
        }
    }
    dragen2 {      
        process {
            withLabel: 'dragen' {
                queue = { "dragen-2" }
                memory  = 200.GB
                cpus = 20
                time = 16.h
                clusterOptions = { "-a 'gtac-mgi-dragen(${params.dragen_container})' -m compute1-dragen-2 -G ${params.user_group} -g ${params.job_group_name} -env 'all, LSF_DOCKER_DRAGEN=y'" }
                ext.intermediate_dir = '/staging/intermediate-results-dir'
            }
        }
    }

    dragen4 {
        process {
            withLabel: 'dragen' {
                queue = { "dragen-4" }
                memory  = 400.GB
                cpus = 30
                time = 16.h                
                clusterOptions = { "-a 'gtac-mgi-dragen(${params.dragen_container})' -m compute1-dragen-4 -G ${params.user_group} -g ${params.job_group_name} -env 'all, LSF_DOCKER_DRAGEN=y'" }
                ext.intermediate_dir = '/staging/intermediate-results-dir'
            }
        }
    }

    dragenaws {
        process {
            withLabel: dragenalign {
                executor                = 'awsbatch'
                ext.dragen_aws_image    = "${params.aws_dragen_container}"
                ext.dragen_license_args = "--lic-server 'https://${secrets.AWS_DRAGEN_USER}:${secrets.AWS_DRAGEN_PASSWORD}@license.edicogenome.com'"
                queue                   = 'nextflow-dragen-aws-queue'
                containerOptions        = '--privileged --ulimit nofile=65535:65535 --ulimit nproc=16384:16384'
                maxErrors               = 1
                cpus                    = 16
                memory                  = 230.GB
                time                    = 24.h
                ext.intermediate_dir    = null
            }
        }
    }

    debug {
        dumpHashes             = true
        process.beforeScript   = 'echo $HOSTNAME'
        cleanup                = false
        nextflow.enable.configProcessNamesValidation = true
    }
    conda {
        conda.enabled          = true
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
        channels               = ['conda-forge', 'bioconda', 'defaults']
        apptainer.enabled      = false
    }
    mamba {
        conda.enabled          = true
        conda.useMamba         = true
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
        apptainer.enabled      = false
    }
    docker {
        docker.enabled         = true
        conda.enabled          = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
        apptainer.enabled      = false
        docker.runOptions      = '-u $(id -u):$(id -g)'
    }
    arm {
        docker.runOptions      = '-u $(id -u):$(id -g) --platform=linux/amd64'
    }
    singularity {
        singularity.enabled    = true
        singularity.autoMounts = true
        conda.enabled          = false
        docker.enabled         = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
        apptainer.enabled      = false
    }
    podman {
        podman.enabled         = true
        conda.enabled          = false
        docker.enabled         = false
        singularity.enabled    = false
        shifter.enabled        = false
        charliecloud.enabled   = false
        apptainer.enabled      = false
    }
    shifter {
        shifter.enabled        = true
        conda.enabled          = false
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        charliecloud.enabled   = false
        apptainer.enabled      = false
    }
    charliecloud {
        charliecloud.enabled   = true
        conda.enabled          = false
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        apptainer.enabled      = false
    }
    apptainer {
        apptainer.enabled      = true
        apptainer.autoMounts   = true
        conda.enabled          = false
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
    }
    gitpod {
        executor.name          = 'local'
        executor.cpus          = 4
        executor.memory        = 8.GB
    }
    test      { includeConfig 'conf/test.config'      }
    test_full { includeConfig 'conf/test_full.config' }
}
// Set default registry for Apptainer, Docker, Podman and Singularity independent of -profile
// Will not be used unless Apptainer / Docker / Podman / Singularity are enabled
// Set to your registry if you have a mirror of containers
apptainer.registry   = 'quay.io'
docker.registry      = 'quay.io'
podman.registry      = 'quay.io'
singularity.registry = 'quay.io'

// Nextflow plugins
plugins {
    id 'nf-validation@1.1.3' // Validation of pipeline parameters and creation of an input channel from a sample sheet
}

// Load igenomes.config if required
if (!params.igenomes_ignore) {
    includeConfig 'conf/igenomes.config'
} else {
    params.genomes = [:]
}
// Export these variables to prevent local Python/R libraries from conflicting with those in the container
// The JULIA depot path has been adjusted to a fixed path `/usr/local/share/julia` that needs to be used for packages in the container.
// See https://apeltzer.github.io/post/03-julia-lang-nextflow/ for details on that. Once we have a common agreement on where to keep Julia packages, this is adjustable.

env {
    PYTHONNOUSERSITE = 1
    R_PROFILE_USER   = "/.Rprofile"
    R_ENVIRON_USER   = "/.Renviron"
    JULIA_DEPOT_PATH = "/usr/local/share/julia"
}

// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']

// Disable process selector warnings by default. Use debug profile to enable warnings.
nextflow.enable.configProcessNamesValidation = false

def trace_timestamp = new java.util.Date().format( 'yyyy-MM-dd_HH-mm-ss')
timeline {
    enabled = true
    file    = "${params.outdir}/pipeline_info/execution_timeline_${trace_timestamp}.html"
}
report {
    enabled = true
    file    = "${params.outdir}/pipeline_info/execution_report_${trace_timestamp}.html"
}
trace {
    enabled = true
    file    = "${params.outdir}/pipeline_info/execution_trace_${trace_timestamp}.txt"
}
dag {
    enabled = true
    file    = "${params.outdir}/pipeline_info/pipeline_dag_${trace_timestamp}.html"
}

manifest {
    name            = 'nf-core/scge'
    author          = """Nidhi"""
    homePage        = 'https://github.com/nf-core/scge'
    description     = """Nextflow implementation of scge workflow"""
    mainScript      = 'main.nf'
    nextflowVersion = '!>=23.04.0'
    version         = '1.0dev'
    doi             = ''
}

// Load modules.config for DSL2 module specific options
includeConfig 'conf/modules.config'

// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}
